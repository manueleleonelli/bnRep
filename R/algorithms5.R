#' algorithms Bayesian Networks
#'
#'
#' Entropy and the Kullback-Leibler divergence for Bayesian networks: Computational complexity and efficient implementation.
#' @usage NULL
#'
#' @format
#' A conditional linear Gaussian Bayesian network to illustrate the algorithms developed in the associated paper (Figure 3, top). The probabilities were available from a repository. The vertices are:
#' \describe{
#' \item{X1}{(a, b);}
#' \item{X2}{(c, d);}
#' \item{X3}{(e, f);}
#' \item{X4}{}
#' \item{X5}{}
#' \item{X6}{}
#'  }
#'
#' @return An object of class \code{bn.fit}. Refer to the documentation of \code{bnlearn} for details.
#' @keywords CLGBN
#' @importClassesFrom bnlearn bn.fit
#' @references Scutari, M. (2024). Entropy and the Kullback-Leibler Divergence for Bayesian Networks: Computational Complexity and Efficient Implementation. Algorithms, 17(1), 24.
"algorithms5"
